---
title: "HW5"
author: "Jianyou Liu"
date: "November 6, 2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))


```
## Problem 1
### Create tidy dataframe

#### Generate dataframe containing all file names

```{r}
# Create dataframe containing all 20 file names in the directory
file_df = tibble(
  list.files(path = ".//data", all.files = FALSE)) 
  
names(file_df)[1] = "file_name"

file_df
```

#### Iterate over file names and load data for each subject as nested list columns

```{r}
#  Read in observation data for each subject as list columns
combine_df = 
  file_df %>%
  mutate(file_path = paste(".//data//", file_name, sep = "")) %>% 
  mutate(data = map(.x = file_path, ~read_csv(file = .x)))

combine_df
  
```
#### Tidy resulting dataset

```{r}
# Clean data for exploratory analysis
clean_df = combine_df %>% 
  mutate(file_name = str_replace(file_name, ".csv$", "")) %>% 
  separate(file_name, into = c("arm", "subject_id"), sep = "_") %>% 
  unnest() %>% 
  gather(key = week, value = observation, week_1:week_8) %>% 
  mutate(week = str_replace(week, "^week_", ""), week = as.numeric(week)) %>% 
  select(-file_path) %>% 
  arrange(arm, subject_id)

# First 10 rows of tidy dataset
print(clean_df, 10)
  
```
### Plot observations on each subject over time
```{r}
# Make spaghetti plot
clean_df %>% 
  ggplot(aes(x = week, y = observation, color = subject_id)) +
  geom_point(alpha = .5) + geom_line() +
  facet_grid(.~arm) +
  labs(
    title = "Comparison of Observation for each Subject Over Time \n Between Control and Experimental Group",
    x = "Week",
    y = "Observation Units"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

**Comment:** Overall, subjects in the experimental arm show higher observation units over time, on average, than those in the control arm. Moreover, observations for the subjects in the experimental group appears to be increasing over time; whereas no apparent pattern exists for the control group.

## Problem 2
### Read and describe raw data

```{r}
raw_hom_data = read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

head(raw_hom_data)
```
The raw dataset is of size `r dim(raw_hom_data)` with `r nrow(raw_hom_data)` observations and `r ncol(raw_hom_data)` variables. Each observation/row represents a single criminal homicide inflicted to a victim. Some key variables include the geographic location of each case, whether an arrest was made, and basic demographic information about each victim.

#### Create city_state variable and summarize total number of homicides as well as the number of unsolved ones.

```{r}
# Merge city and state into one variable
new_hom_data = raw_hom_data %>% 
  unite(city, state, col = "city_state", sep = ",")

# Summarize within cities to find number of homicide 
tot_hom_data = new_hom_data %>% 
  group_by(city_state) %>% 
  summarize(total_homicide = n())

# Summarize within cities to find number of unsolved crimes
unsolv_hom_data = new_hom_data %>% 
  filter(disposition == "Closed without arrest" | disposition == "Open/No arrest") %>% 
  group_by(city_state) %>% 
  summarize(unsolved_homicides = n())
  
# Join datasets
city_hom_data = left_join(tot_hom_data, unsolv_hom_data, by = "city_state")

# First 10 rows of resulting dataset
print(city_hom_data, 10)

```
### Baltimore, MD Analysis
#### Estimate proportion and confidence intervals

```{r}
# Run prop.test for Baltimore, MD
balt_prop_test = prop.test(1825, 2827, p = 0.5, conf.level = 0.95)
tidy_output = broom::tidy(balt_prop_test)
 
# Pull estimate and CI from resulting tidy dataframe
est_prop = pull(tidy_output, estimate)
low_CI = pull(tidy_output, conf.low)
high_CI = pull(tidy_output, conf.high)

```
According to the results of the test, the *point estimate* of the proportion of unsolved crimes in Baltimore, MD is **`r est_prop`**; and we can be *95% confident* that the true proportion of unsolved homicides in this city is between **`r low_CI`** and **`r high_CI`**

### All City Analysis
#### Estimate proportions and CIs for each city

```{r}
# Run prop.test for every city excluding Tulsa and store result as a list column
test_data = city_hom_data %>% 
  filter(city_state != "Tulsa,AL") %>% 
  mutate(test_stats = map2(.x = unsolved_homicides, .y = total_homicide, ~prop.test(x = .x, n= .y) %>% broom::tidy())) %>% 
# Unnest to extract estimates and CIs for each city
unnest() %>% 
  select(city_state, total_homicide, unsolved_homicides, estimate, conf.low, conf.high)

# First few rows of resulting data frame
head(test_data)
  
  
 
```


